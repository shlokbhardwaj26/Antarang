{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7251,"sourceType":"datasetVersion","datasetId":2798},{"sourceId":1351797,"sourceType":"datasetVersion","datasetId":786787},{"sourceId":1732825,"sourceType":"datasetVersion","datasetId":1028436},{"sourceId":7715066,"sourceType":"datasetVersion","datasetId":4505684}],"dockerImageVersionId":30646,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nimport keras\nfrom keras.preprocessing import image\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D, Flatten,Dense,Dropout,BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom tensorflow.keras.applications import VGG16, InceptionResNetV2\nfrom keras import regularizers\nfrom tensorflow.keras.optimizers import Adam,RMSprop,SGD,Adamax","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-27T18:44:06.898387Z","iopub.execute_input":"2024-02-27T18:44:06.898764Z","iopub.status.idle":"2024-02-27T18:44:22.953345Z","shell.execute_reply.started":"2024-02-27T18:44:06.898734Z","shell.execute_reply":"2024-02-27T18:44:22.952060Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-02-27 18:44:11.412187: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-27 18:44:11.412357: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-27 18:44:11.543789: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dir = \"../input/emotion-detection-fer/train\" #passing the path with training images\ntest_dir = \"../input/emotion-detection-fer/test\"   #passing the path with testing images","metadata":{"execution":{"iopub.status.busy":"2024-02-27T18:44:22.956102Z","iopub.execute_input":"2024-02-27T18:44:22.956796Z","iopub.status.idle":"2024-02-27T18:44:22.961814Z","shell.execute_reply.started":"2024-02-27T18:44:22.956762Z","shell.execute_reply":"2024-02-27T18:44:22.960817Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"img_size = 48 ","metadata":{"execution":{"iopub.status.busy":"2024-02-27T18:44:22.963617Z","iopub.execute_input":"2024-02-27T18:44:22.966571Z","iopub.status.idle":"2024-02-27T18:44:22.981930Z","shell.execute_reply.started":"2024-02-27T18:44:22.966530Z","shell.execute_reply":"2024-02-27T18:44:22.981017Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(#rotation_range = 180,\n                                         width_shift_range = 0.1,\n                                         height_shift_range = 0.1,\n                                         horizontal_flip = True,\n                                         rescale = 1./255,\n                                         #zoom_range = 0.2,\n                                         validation_split = 0.2\n                                        )\nvalidation_datagen = ImageDataGenerator(rescale = 1./255,\n                                         validation_split = 0.2)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T18:44:22.983103Z","iopub.execute_input":"2024-02-27T18:44:22.983605Z","iopub.status.idle":"2024-02-27T18:44:22.991365Z","shell.execute_reply.started":"2024-02-27T18:44:22.983573Z","shell.execute_reply":"2024-02-27T18:44:22.990585Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(directory = train_dir,\n                                                    target_size = (img_size,img_size),\n                                                    batch_size = 64,\n                                                    color_mode = \"grayscale\",\n                                                    class_mode = \"categorical\",\n                                                    subset = \"training\"\n                                                   )\nvalidation_generator = validation_datagen.flow_from_directory( directory = test_dir,\n                                                              target_size = (img_size,img_size),\n                                                              batch_size = 64,\n                                                              color_mode = \"grayscale\",\n                                                              class_mode = \"categorical\",\n                                                              subset = \"validation\"\n                                                             )","metadata":{"execution":{"iopub.status.busy":"2024-02-27T18:44:22.994344Z","iopub.execute_input":"2024-02-27T18:44:22.994709Z","iopub.status.idle":"2024-02-27T18:44:44.543683Z","shell.execute_reply.started":"2024-02-27T18:44:22.994674Z","shell.execute_reply":"2024-02-27T18:44:44.542797Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Found 22968 images belonging to 7 classes.\nFound 1432 images belonging to 7 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"model= tf.keras.models.Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(48, 48,1)))\nmodel.add(Conv2D(64,(3,3), padding='same', activation='relu' ))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(128,(5,5), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n    \nmodel.add(Conv2D(512,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(512,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten()) \nmodel.add(Dense(256,activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n    \nmodel.add(Dense(512,activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(7, activation='softmax'))\n\nmodel.compile(\n    optimizer = Adam(lr=0.0001), \n    loss='categorical_crossentropy', \n    metrics=['accuracy']\n  )","metadata":{"execution":{"iopub.status.busy":"2024-02-27T18:44:44.559995Z","iopub.execute_input":"2024-02-27T18:44:44.560372Z","iopub.status.idle":"2024-02-27T18:44:44.988124Z","shell.execute_reply.started":"2024-02-27T18:44:44.560345Z","shell.execute_reply":"2024-02-27T18:44:44.986974Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"epochs = 60\nbatch_size = 64","metadata":{"execution":{"iopub.status.busy":"2024-02-27T18:44:44.989539Z","iopub.execute_input":"2024-02-27T18:44:44.989928Z","iopub.status.idle":"2024-02-27T18:44:44.994836Z","shell.execute_reply.started":"2024-02-27T18:44:44.989893Z","shell.execute_reply":"2024-02-27T18:44:44.993896Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-02-27T18:44:44.996924Z","iopub.execute_input":"2024-02-27T18:44:44.997774Z","iopub.status.idle":"2024-02-27T18:44:45.076350Z","shell.execute_reply.started":"2024-02-27T18:44:44.997737Z","shell.execute_reply":"2024-02-27T18:44:45.075270Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 48, 48, 32)        320       \n                                                                 \n conv2d_1 (Conv2D)           (None, 48, 48, 64)        18496     \n                                                                 \n batch_normalization (Batch  (None, 48, 48, 64)        256       \n Normalization)                                                  \n                                                                 \n max_pooling2d (MaxPooling2  (None, 24, 24, 64)        0         \n D)                                                              \n                                                                 \n dropout (Dropout)           (None, 24, 24, 64)        0         \n                                                                 \n conv2d_2 (Conv2D)           (None, 24, 24, 128)       204928    \n                                                                 \n batch_normalization_1 (Bat  (None, 24, 24, 128)       512       \n chNormalization)                                                \n                                                                 \n max_pooling2d_1 (MaxPoolin  (None, 12, 12, 128)       0         \n g2D)                                                            \n                                                                 \n dropout_1 (Dropout)         (None, 12, 12, 128)       0         \n                                                                 \n conv2d_3 (Conv2D)           (None, 12, 12, 512)       590336    \n                                                                 \n batch_normalization_2 (Bat  (None, 12, 12, 512)       2048      \n chNormalization)                                                \n                                                                 \n max_pooling2d_2 (MaxPoolin  (None, 6, 6, 512)         0         \n g2D)                                                            \n                                                                 \n dropout_2 (Dropout)         (None, 6, 6, 512)         0         \n                                                                 \n conv2d_4 (Conv2D)           (None, 6, 6, 512)         2359808   \n                                                                 \n batch_normalization_3 (Bat  (None, 6, 6, 512)         2048      \n chNormalization)                                                \n                                                                 \n max_pooling2d_3 (MaxPoolin  (None, 3, 3, 512)         0         \n g2D)                                                            \n                                                                 \n dropout_3 (Dropout)         (None, 3, 3, 512)         0         \n                                                                 \n flatten (Flatten)           (None, 4608)              0         \n                                                                 \n dense (Dense)               (None, 256)               1179904   \n                                                                 \n batch_normalization_4 (Bat  (None, 256)               1024      \n chNormalization)                                                \n                                                                 \n dropout_4 (Dropout)         (None, 256)               0         \n                                                                 \n dense_1 (Dense)             (None, 512)               131584    \n                                                                 \n batch_normalization_5 (Bat  (None, 512)               2048      \n chNormalization)                                                \n                                                                 \n dropout_5 (Dropout)         (None, 512)               0         \n                                                                 \n dense_2 (Dense)             (None, 7)                 3591      \n                                                                 \n=================================================================\nTotal params: 4496903 (17.15 MB)\nTrainable params: 4492935 (17.14 MB)\nNon-trainable params: 3968 (15.50 KB)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"history = model.fit(x = train_generator,epochs = epochs,validation_data = validation_generator)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T18:44:45.077944Z","iopub.execute_input":"2024-02-27T18:44:45.078374Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/60\n359/359 [==============================] - 543s 2s/step - loss: 5.1857 - accuracy: 0.2238 - val_loss: 2.6689 - val_accuracy: 0.2472\nEpoch 2/60\n359/359 [==============================] - 532s 1s/step - loss: 2.2678 - accuracy: 0.3089 - val_loss: 2.2959 - val_accuracy: 0.2395\nEpoch 3/60\n359/359 [==============================] - 533s 1s/step - loss: 2.2551 - accuracy: 0.3866 - val_loss: 2.3244 - val_accuracy: 0.4155\nEpoch 4/60\n359/359 [==============================] - 535s 1s/step - loss: 2.3579 - accuracy: 0.4414 - val_loss: 2.5629 - val_accuracy: 0.3994\nEpoch 5/60\n359/359 [==============================] - 524s 1s/step - loss: 2.2757 - accuracy: 0.4701 - val_loss: 2.2591 - val_accuracy: 0.4825\nEpoch 6/60\n359/359 [==============================] - 528s 1s/step - loss: 2.2369 - accuracy: 0.4862 - val_loss: 2.1611 - val_accuracy: 0.5161\nEpoch 7/60\n359/359 [==============================] - 528s 1s/step - loss: 2.1528 - accuracy: 0.4928 - val_loss: 2.1596 - val_accuracy: 0.5007\nEpoch 8/60\n359/359 [==============================] - 526s 1s/step - loss: 2.1396 - accuracy: 0.4990 - val_loss: 2.1524 - val_accuracy: 0.5028\nEpoch 9/60\n359/359 [==============================] - 524s 1s/step - loss: 2.1253 - accuracy: 0.5040 - val_loss: 2.0785 - val_accuracy: 0.4749\nEpoch 10/60\n359/359 [==============================] - 542s 2s/step - loss: 2.0401 - accuracy: 0.5121 - val_loss: 2.0588 - val_accuracy: 0.5223\nEpoch 11/60\n359/359 [==============================] - 562s 2s/step - loss: 2.0484 - accuracy: 0.5161 - val_loss: 1.8293 - val_accuracy: 0.5531\nEpoch 12/60\n359/359 [==============================] - 569s 2s/step - loss: 1.9995 - accuracy: 0.5206 - val_loss: 2.0872 - val_accuracy: 0.4923\nEpoch 13/60\n359/359 [==============================] - 566s 2s/step - loss: 1.9926 - accuracy: 0.5214 - val_loss: 1.9987 - val_accuracy: 0.5244\nEpoch 14/60\n359/359 [==============================] - 564s 2s/step - loss: 1.9472 - accuracy: 0.5253 - val_loss: 1.9842 - val_accuracy: 0.5440\nEpoch 15/60\n359/359 [==============================] - 564s 2s/step - loss: 1.9591 - accuracy: 0.5345 - val_loss: 1.9342 - val_accuracy: 0.5321\nEpoch 16/60\n359/359 [==============================] - 560s 2s/step - loss: 1.9442 - accuracy: 0.5381 - val_loss: 1.9956 - val_accuracy: 0.5468\nEpoch 17/60\n359/359 [==============================] - 561s 2s/step - loss: 1.9266 - accuracy: 0.5404 - val_loss: 1.8868 - val_accuracy: 0.5489\nEpoch 18/60\n359/359 [==============================] - 560s 2s/step - loss: 1.8243 - accuracy: 0.5386 - val_loss: 1.7671 - val_accuracy: 0.5796\nEpoch 19/60\n359/359 [==============================] - 561s 2s/step - loss: 1.8703 - accuracy: 0.5457 - val_loss: 1.7007 - val_accuracy: 0.5747\nEpoch 20/60\n359/359 [==============================] - 561s 2s/step - loss: 1.8166 - accuracy: 0.5455 - val_loss: 1.7085 - val_accuracy: 0.5649\nEpoch 21/60\n359/359 [==============================] - 562s 2s/step - loss: 1.8164 - accuracy: 0.5509 - val_loss: 1.7357 - val_accuracy: 0.5705\nEpoch 22/60\n359/359 [==============================] - 561s 2s/step - loss: 1.7996 - accuracy: 0.5545 - val_loss: 1.7651 - val_accuracy: 0.5489\nEpoch 23/60\n359/359 [==============================] - 561s 2s/step - loss: 1.8339 - accuracy: 0.5513 - val_loss: 1.6745 - val_accuracy: 0.5663\nEpoch 24/60\n359/359 [==============================] - 561s 2s/step - loss: 1.7164 - accuracy: 0.5595 - val_loss: 1.6500 - val_accuracy: 0.5817\nEpoch 25/60\n359/359 [==============================] - 559s 2s/step - loss: 1.6706 - accuracy: 0.5616 - val_loss: 1.7122 - val_accuracy: 0.5510\nEpoch 26/60\n359/359 [==============================] - 560s 2s/step - loss: 1.6289 - accuracy: 0.5618 - val_loss: 1.6398 - val_accuracy: 0.5831\nEpoch 27/60\n359/359 [==============================] - 561s 2s/step - loss: 1.6195 - accuracy: 0.5630 - val_loss: 1.5287 - val_accuracy: 0.6006\nEpoch 28/60\n359/359 [==============================] - 561s 2s/step - loss: 1.6053 - accuracy: 0.5648 - val_loss: 1.6051 - val_accuracy: 0.5908\nEpoch 29/60\n359/359 [==============================] - 562s 2s/step - loss: 1.5505 - accuracy: 0.5711 - val_loss: 1.6755 - val_accuracy: 0.5216\nEpoch 30/60\n359/359 [==============================] - 561s 2s/step - loss: 1.5670 - accuracy: 0.5677 - val_loss: 1.5357 - val_accuracy: 0.5754\nEpoch 31/60\n359/359 [==============================] - 559s 2s/step - loss: 1.5569 - accuracy: 0.5718 - val_loss: 1.5285 - val_accuracy: 0.5754\nEpoch 32/60\n359/359 [==============================] - 558s 2s/step - loss: 1.5680 - accuracy: 0.5682 - val_loss: 1.5039 - val_accuracy: 0.5992\nEpoch 33/60\n359/359 [==============================] - 561s 2s/step - loss: 1.5748 - accuracy: 0.5688 - val_loss: 1.5656 - val_accuracy: 0.5594\nEpoch 34/60\n359/359 [==============================] - 561s 2s/step - loss: 1.5544 - accuracy: 0.5758 - val_loss: 1.5128 - val_accuracy: 0.5922\nEpoch 35/60\n359/359 [==============================] - 561s 2s/step - loss: 1.6072 - accuracy: 0.5695 - val_loss: 1.4928 - val_accuracy: 0.5901\nEpoch 36/60\n359/359 [==============================] - 559s 2s/step - loss: 1.6146 - accuracy: 0.5746 - val_loss: 1.5433 - val_accuracy: 0.5873\nEpoch 37/60\n359/359 [==============================] - 562s 2s/step - loss: 1.5853 - accuracy: 0.5756 - val_loss: 1.4739 - val_accuracy: 0.5971\nEpoch 38/60\n359/359 [==============================] - 560s 2s/step - loss: 1.5216 - accuracy: 0.5778 - val_loss: 1.5702 - val_accuracy: 0.5936\nEpoch 39/60\n359/359 [==============================] - 565s 2s/step - loss: 1.5201 - accuracy: 0.5831 - val_loss: 1.5226 - val_accuracy: 0.5971\nEpoch 40/60\n359/359 [==============================] - 570s 2s/step - loss: 1.5112 - accuracy: 0.5795 - val_loss: 1.5135 - val_accuracy: 0.6006\nEpoch 41/60\n359/359 [==============================] - 571s 2s/step - loss: 1.5027 - accuracy: 0.5821 - val_loss: 1.4928 - val_accuracy: 0.5908\nEpoch 42/60\n359/359 [==============================] - 570s 2s/step - loss: 1.4698 - accuracy: 0.5841 - val_loss: 1.4672 - val_accuracy: 0.5901\nEpoch 43/60\n359/359 [==============================] - 566s 2s/step - loss: 1.4605 - accuracy: 0.5883 - val_loss: 1.3929 - val_accuracy: 0.6250\nEpoch 44/60\n359/359 [==============================] - 567s 2s/step - loss: 1.4815 - accuracy: 0.5864 - val_loss: 1.4692 - val_accuracy: 0.5838\nEpoch 45/60\n359/359 [==============================] - 566s 2s/step - loss: 1.4702 - accuracy: 0.5854 - val_loss: 1.3897 - val_accuracy: 0.6110\nEpoch 46/60\n359/359 [==============================] - 567s 2s/step - loss: 1.4643 - accuracy: 0.5848 - val_loss: 1.5335 - val_accuracy: 0.5775\nEpoch 47/60\n359/359 [==============================] - 566s 2s/step - loss: 1.5261 - accuracy: 0.5823 - val_loss: 1.4896 - val_accuracy: 0.5824\nEpoch 48/60\n359/359 [==============================] - 566s 2s/step - loss: 1.4716 - accuracy: 0.5878 - val_loss: 1.4184 - val_accuracy: 0.6194\nEpoch 49/60\n359/359 [==============================] - 566s 2s/step - loss: 1.4486 - accuracy: 0.5937 - val_loss: 1.4271 - val_accuracy: 0.5964\nEpoch 50/60\n359/359 [==============================] - 566s 2s/step - loss: 1.4415 - accuracy: 0.5936 - val_loss: 1.4831 - val_accuracy: 0.5978\nEpoch 51/60\n359/359 [==============================] - 566s 2s/step - loss: 1.4643 - accuracy: 0.5872 - val_loss: 1.4392 - val_accuracy: 0.5999\nEpoch 52/60\n359/359 [==============================] - 565s 2s/step - loss: 1.4602 - accuracy: 0.5970 - val_loss: 1.4490 - val_accuracy: 0.5859\nEpoch 53/60\n359/359 [==============================] - 566s 2s/step - loss: 1.4527 - accuracy: 0.5911 - val_loss: 1.5628 - val_accuracy: 0.5859\nEpoch 54/60\n359/359 [==============================] - 565s 2s/step - loss: 1.4466 - accuracy: 0.5935 - val_loss: 1.3925 - val_accuracy: 0.5999\nEpoch 55/60\n 29/359 [=>............................] - ETA: 8:28 - loss: 1.4376 - accuracy: 0.5867","output_type":"stream"}]},{"cell_type":"code","source":"fig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nfig.set_size_inches(12,4)\n\nax[0].plot(history.history['accuracy'])\nax[0].plot(history.history['val_accuracy'])\nax[0].set_title('Training Accuracy vs Validation Accuracy')\nax[0].set_ylabel('Accuracy')\nax[0].set_xlabel('Epoch')\nax[0].legend(['Train', 'Validation'], loc='upper left')\n\nax[1].plot(history.history['loss'])\nax[1].plot(history.history['val_loss'])\nax[1].set_title('Training Loss vs Validation Loss')\nax[1].set_ylabel('Loss')\nax[1].set_xlabel('Epoch')\nax[1].legend(['Train', 'Validation'], loc='upper left')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = image.load_img(\"/kaggle/input/testing-image/TESTING123.jpg\",target_size = (48,48),color_mode = \"grayscale\")\nimg = np.array(img)\nplt.imshow(img)\nprint(img.shape) #prints (48,48) that is the shape of our image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_dict = {0:'Angry',1:'Disgust',2:'Fear',3:'Happy',4:'Neutral',5:'Sad',6:'Surprise'}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = np.expand_dims(img,axis = 0) #makes image shape (1,48,48)\nimg = img.reshape(1,48,48,1)\nresult = model.predict(img)\nresult = list(result[0])\nprint(result)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_index = result.index(max(result))\nprint(label_dict[img_index])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss, train_acc = model.evaluate(train_generator)\ntest_loss, test_acc   = model.evaluate(validation_generator)\nprint(\"final train accuracy = {:.2f} , validation accuracy = {:.2f}\".format(train_acc*100, test_acc*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_weights('model_weights.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}